
### ping-ponging 



::: {.r-stack .my-full}
![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-1.svg){.fragment .fade-in-then-out fragment-index=1}

![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-2.svg){.fragment .fade-in-then-out fragment-index=2}

![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-3.svg){.fragment .fade-in-then-out fragment-index=3}

![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-4.svg){.fragment .fade-in-then-out fragment-index=4}

![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-5.svg){.fragment .fade-in-then-out fragment-index=5}

![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-6.svg){.fragment .fade-in-then-out fragment-index=6}

![](/sync-lock-impl/texfig/test-and-test-and-set-ping-ponging.figure-7.svg){.fragment .fade-in-then-out fragment-index=7}


:::


### ping-ponging  {.smaller}


* test-and-set problem: cache block ‘‘ping-pongs’’ between caches 

   * each waiting processor reserves block to modify
   * could maybe wait until it determines modification needed --- but not typical implementation

* each transfer of block sends messages on bus
* … so bus can't be used for real work 

   * like what the processor with the lock is doing



### test-and-test-and-set (pseudo-C) 


```
acquire(int *the_lock) {
    do {
        while (ATOMIC-READ(the_lock) == 0) { /* try again */ }
    } while (ATOMIC-TEST-AND-SET(the_lock) == ALREADY_SET);
}

```


### test-and-test-and-set (assembly)  {.smaller}


```
acquire:
    cmp $0, the_lock         // test the lock non-atomically
            // unlike lock xchg --- keeps lock in Shared state!
    jne acquire              // try again (still locked)
    // lock possibly free
    // but another processor might lock
    // before we get a chance to
    // ... so try wtih atomic swap:
    movl $1, %eax             // %eax <- 1
    lock xchg %eax, the_lock  // swap %eax and the_lock
           // sets the_lock to 1
           // sets %eax to prior value of the_lock
    test %eax, %eax           // if the_lock wasn't 0 (someone else got it first):
    jne acquire               //   try again
    ret

```


### less ping-ponging 



::: {.r-stack .my-full}
![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-1.svg){.fragment .fade-in-then-out fragment-index=1}

![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-2.svg){.fragment .fade-in-then-out fragment-index=2}

![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-3.svg){.fragment .fade-in-then-out fragment-index=3}

![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-4.svg){.fragment .fade-in-then-out fragment-index=4}

![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-5.svg){.fragment .fade-in-then-out fragment-index=5}

![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-6.svg){.fragment .fade-in-then-out fragment-index=6}

![](/sync-lock-impl/texfig/test-and-test-and-set-less-ping-ponging.figure-7.svg){.fragment .fade-in-then-out fragment-index=7}


:::


### couldn't the read-modify-write instruction\ldots 


* notice that the value of the lock isn't changing…
* and keep it in the shared state 
<hr class="vspace" />
* maybe --- but extra step in ‘‘common’’ case <br> (swapping different values)


### more room for improvement?  {.smaller}


* can still have a lot of attempts to modify locks after unlocked
* there other spinlock designs that avoid this 

   * ticket locks
   * MCS locks
   * …


