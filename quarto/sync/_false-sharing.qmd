
### modifying cache blocks in parallel  {.smaller}


* typical memory access --- less than cache block 

   * e.g. one 4-byte array element in 64-byte cache block
 
<hr class="vspace" />
* what if two processors modify different parts same cache block?  

   * 4-byte writes to 64-byte cache block

* typically how caches work --- write instructions happen one at a time: 

   * processor ‘locks’ 64-byte cache block, fetching latest version
   * processor updates 4 bytes of 64-byte cache block
   * later, processor might give up cache block



### modifying things in parallel (code)  {.smaller}


```
void *sum_up(void *raw_dest) {
    int *dest = (int *) raw_dest;
    for (int i = 0; i < 64 * 1024 * 1024; ++i) {
        *dest += data[i];
    }
}

__attribute__((aligned(4096))) 
int dests[1024];  /* aligned = address is mult. of 4096 */

void sum_twice(int distance) {
    pthread_t threads[2];
    pthread_create(&threads[0], NULL, sum_up, &dests[0]);
    pthread_create(&threads[1], NULL, sum_up, &dests[distance]);
    pthread_join(threads[0], NULL);
    pthread_join(threads[1], NULL);
}

```


### performance v. array element gap 

(assuming <code>sum_up</code> compiled to not omit memory accesses) 
![](/sync/sum-up){}


### false sharing 


* synchronizing to access two independent things 
<hr class="vspace" />
* two parts of same cache block
* solution: separate them

